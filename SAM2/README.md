# SAM2
## 说明  
SAM2(segment anything2), 是由Meta开发的一个先进的图像和视频分割模型  
- 支持视频分割：SAM2的一个重要进展是它的能力从图像分割扩展到了视频分割。这意味着它能够处理视频中的对象，而不仅仅是静态图像。
- 实时处理任意长视频：SAM2能够实时处理任意长度的视频，这在实际应用中非常有用，尤其是在需要快速响应的场景中。
- Zero-shot泛化：即使是在视频中没有见过的对象，SAM2也能实现有效的分割和追踪，这显示了其强大的泛化能力。
- 分割和追踪准确性提升：与第一代模型相比，SAM2在分割和追踪准确性方面有了显著提升。 
- 解决遮挡问题：在视频分割中，对象可能会被遮挡，SAM2能够有效地处理这种情况，即使在物体暂时遮挡的情况下也能帮助分割物体。
- 交互式分割过程：SAM2的分割过程是交互式的，用户可以通过点击来选择和细化目标对象，模型会根据这些提示自动将分割传播到视频的后续帧。
- 引入记忆模块：为了处理视频中的对象，SAM2引入了流式记忆模块，这使得模型能够利用先前帧的信息来辅助当前帧的分割任务。
- 数据集和模型的开源：Meta此次开源的数据集包含51000个真实世界视频和600000个时空掩码，这是迄今为止同类数据集中规模最大的。同时，模型代码、权重和数据集均遵循Apache 2.0许可协议开源。  
这个GUI目前只实现了按关键点进行分割，基于bounding-box分割和视频分割尚未实现
##  使用方法
运行SAM2的GUI，使用这个工具需要：
1. 从https://github.com/facebookresearch/sam2 克隆仓库(比如叫SAM2)，并下载对应的模型
2. 将GUI.py复制到仓库根路径下,即"SAM2/"
3. 运行脚本，加载图片(可多选)，通过鼠标点击设置关键点，点击“执行分割”，如果觉得效果可以，点击“保存”按钮进行保存